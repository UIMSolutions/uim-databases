module rtad-example;

/// Real-time Analytical Database Examples
/// Demonstrates time-series ingestion, aggregations, and analytics

import std.stdio;
import std.datetime;
import std.random;
import std.algorithm;
import std.array;
import vibe.data.json;
import uim.databases.rtad;

void main() {
    writeln("=== Real-time Analytical Database Examples ===\n");
    
    // Example 1: Initialize storage and processor
    writeln("Example 1: Initialize RTAD components");
































































































































































































import std.range : reduce;}    writeln("=== Examples Complete ===");        writef("Stream processor stopped\n\n");    processor.stop();    writeln("Example 18: Shutdown processor");    // Example 18: Cleanup and shutdown        writef("\n");    }        writef("  Range: %.2f - %.2f°C\n", tempAgg.min, tempAgg.max);        writef("  Average: %.2f°C\n", tempAgg.mean);        writef("Temperature aggregation:\n");        auto tempAgg = AggregationEngine.aggregate("temperature", ["location": "room-a"], values);        auto values = tempSeries.values();    if (tempSeries) {    auto tempSeries = storage.getTimeSeries("temperature", ["location": "room-a"]);        processor.flush();    processor.pushDataPoints(workflow);    }        workflow ~= DataPoint(ts, "temperature", 20.0 + uniform(-2.0, 2.0), ["location": "room-a"]);        auto ts = Clock.currTime() + dur!"seconds"(i);    for (int i = 0; i < 50; i++) {    DataPoint[] workflow;    writeln("Example 17: End-to-end aggregation workflow");    // Example 17: Data aggregation workflow        writef("  Avg points per series: %.0f\n\n", totalSeries > 0 ? cast(double)totalPoints / totalSeries : 0.0);    writef("  Points: %d\n", totalPoints);    writef("  Series: %d\n", totalSeries);    writef("Final Statistics:\n");    auto totalPoints = storage.totalPointCount;    auto totalSeries = storage.seriesCount;    writeln("Example 16: Batch metrics statistics");    // Example 16: Batch statistics        writef("Stored metric with tags: service=%s, region=%s\n\n", tags["service"], tags["region"]);    processor.flush();    processor.pushDataPoint(taggedPoint);    auto taggedPoint = DataPoint(Clock.currTime(), "request.latency", 245.3, tags);    string[string] tags = ["service": "api", "region": "us-west", "instance": "prod-1"];    writeln("Example 15: Tags for multi-dimensional data");    // Example 15: Time-series with tags        writef("CPU series in last hour: %d\n\n", recentSeries.length);    auto recentSeries = storage.queryMetrics("cpu.usage", oneHourBack, Clock.currTime());    auto oneHourBack = Clock.currTime() - dur!"hours"(1);    writeln("Example 14: Query latest 1-hour values");    // Example 14: Query latest values        writef("Total points: %d\n\n", storage.totalPointCount);    writef("Total series: %d\n", storage.seriesCount);    writef("Storage name: %s\n", storage.name);    writeln("Example 13: Storage statistics");    // Example 13: Storage statistics        writef("Total series: %d\n\n", storage.seriesCount);    writef("Added metrics from 3 hosts\n");    processor.flush();    processor.pushDataPoints(multiHost);        }            ["host": "server-" ~ to!string(host), "region": "us-east"]);        multiHost ~= DataPoint(timestamp, "cpu.usage", cpuValue,         import std.conv : to;                double cpuValue = 30.0 + host * 10.0 + uniform(-5.0, 5.0);        auto timestamp = Clock.currTime();    for (int host = 1; host <= 3; host++) {    DataPoint[] multiHost;    writeln("Example 12: Multi-host metrics");    // Example 12: Push multiple hosts        }        writef("Points in 30-10 minute window: %d\n\n", points.length);        auto points = windowData.pointsBetween(windowStart, windowEnd);    if (windowData) {    auto windowData = storage.getTimeSeries("memory.usage", ["host": "server-1"]);    auto windowEnd = now - dur!"minutes"(10);    auto windowStart = now - dur!"minutes"(30);    writeln("Example 11: Query specific window");    // Example 11: Query by time window        }        writef("Average rate of change: %.2f\n\n", avgRate);        double avgRate = rates.empty ? 0 : reduce!((a, b) => a + b)(rates) / rates.length;        auto rates = AggregationEngine.calculateRate(values);        auto values = cpuSeries.values();    if (cpuSeries) {    writeln("Example 10: Calculate rate of change");    // Example 10: Rate of change        writef("\n");    }        writef("EWMA (alpha=0.3): latest=%.2f\n", ewma.empty ? 0.0 : ewma[$ - 1]);        auto ewma = AggregationEngine.ewma(values, 0.3);        auto values = cpuSeries.values();    if (cpuSeries) {    writeln("Example 9: Exponential weighted moving average");    // Example 9: Exponential weighted moving average        writef("\n");    }        writef("Moving average (window=5): %.2f values\n", ma.empty ? 0.0 : ma[$ / 2]);        auto ma = AggregationEngine.movingAverage(values, 5);        auto values = cpuSeries.values();    if (cpuSeries) {    writeln("Example 8: Calculate moving average");    // Example 8: Moving average        writef("\n");    }            agg.percentiles[0], agg.percentiles[1], agg.percentiles[2], agg.percentiles[3]);        writef("  P50: %.2f, P75: %.2f, P95: %.2f, P99: %.2f\n",        writef("  StdDev: %.2f\n", agg.stddev);        writef("  Max: %.2f\n", agg.max);        writef("  Min: %.2f\n", agg.min);        writef("  Mean: %.2f\n", agg.mean);        writef("  Sum: %.2f\n", agg.sum);        writef("  Count: %d\n", agg.count);        writef("CPU Aggregations:\n");                auto agg = AggregationEngine.aggregate("cpu.usage", ["host": "server-1"], values);        auto values = cpuSeries.values();    if (cpuSeries) {    auto cpuSeries = storage.getTimeSeries("cpu.usage", ["host": "server-1"]);    writeln("Example 7: Calculate aggregations");    // Example 7: Calculate aggregations        writef("\n");    }        writef("  - %s\n", m);    foreach (m; metrics) {    writef("Available metrics:\n");    auto metrics = storage.getAllMetrics();    writeln("Example 6: Get available metrics");    // Example 6: Get all available metrics        writef("\n");    }        writef("  %s: %d points\n", ts.metric, ts.pointCount);    foreach (ts; series[0 .. min(3, series.length)]) {    writef("Found %d metric series matching '*'\n", series.length);    auto series = storage.queryMetrics("*", oneHourAgo, now);    auto oneHourAgo = now - dur!"hours"(1);    writeln("Example 5: Query metrics by pattern");    // Example 5: Query metrics by pattern        writef("  Total points: %d\n\n", storage.totalPointCount);    writef("  Series: %d\n", storage.seriesCount);    writef("Buffer flushed. Storage now contains:\n");    processor.flush();    writeln("Example 4: Flush to storage");    // Example 4: Flush data to storage        writef("Buffer size: %d\n\n", processor.bufferLength);    writef("Pushed %d metrics in batch\n", batch.length);    processor.pushDataPoints(batch);        }        batch ~= DataPoint(timestamp, "memory.usage", memValue, ["host": "server-1"]);        batch ~= DataPoint(timestamp, "cpu.usage", cpuValue, ["host": "server-1"]);                double memValue = 60.0 + (uniform(-15.0, 15.0));        double cpuValue = 40.0 + (uniform(-10.0, 10.0));        auto timestamp = now + dur!"seconds"(i);    for (int i = 0; i < 100; i++) {    DataPoint[] batch;    writeln("Example 3: Push batch of metrics");    // Example 3: Push batch of metrics        writef("Pushed 3 individual metrics\n\n");    processor.pushDataPoint(diskMetric);    processor.pushDataPoint(memoryMetric);    processor.pushDataPoint(cpuMetric);        auto diskMetric = DataPoint(now, "disk.io", 150.5, ["host": "server-1", "device": "sda"]);    auto memoryMetric = DataPoint(now, "memory.usage", 62.1, ["host": "server-1", "region": "us-east"]);    auto cpuMetric = DataPoint(now, "cpu.usage", 45.3, ["host": "server-1", "region": "us-east"]);        auto now = Clock.currTime();    writeln("Example 2: Push single metrics");    // Example 2: Push single metrics        writef("Initialized: Storage, Processor, Query Engine\n\n");    processor.start();        auto queryEngine = new QueryEngine(storage);    auto storage = new TimeSeriesStorage("monitoring", 1_000_000);
    auto processor = new StreamProcessor(storage, 5_000, 500);